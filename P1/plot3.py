# Archivo: plot_training_results.py

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import os

# ==================== CONFIGURACI√ìN ====================
LOGS_DIR = "logs/"
MODEL_NAME = "ppo_robobo_v2"
OUTPUT_DIR = "plots/"

os.makedirs(OUTPUT_DIR, exist_ok=True)

# ==================== LEER DATOS DEL MONITOR ====================
monitor_file = os.path.join(LOGS_DIR, f"{MODEL_NAME}_monitor.monitor.csv")

print("="*60)
print("GENERANDO GR√ÅFICAS DE ENTRENAMIENTO")
print("="*60)

if not os.path.exists(monitor_file):
    print(f"\n‚ùå No se encontr√≥ el archivo: {monitor_file}")
    print(f"\nüí° Buscando archivos en {LOGS_DIR}...")
    
    if os.path.exists(LOGS_DIR):
        print(f"\nüìÅ Archivos disponibles:")
        for f in os.listdir(LOGS_DIR):
            print(f"   - {f}")
    else:
        print(f"   ‚ùå El directorio {LOGS_DIR} no existe")
    
    print("\n‚ö†Ô∏è  Aseg√∫rate de haber ejecutado train_improved.py primero")
    exit(1)

# Leer CSV (saltar primera l√≠nea que es metadata)
try:
    df = pd.read_csv(monitor_file, skiprows=1)
    print(f"\n‚úÖ Datos cargados: {len(df)} episodios")
    print(f"Columnas: {df.columns.tolist()}")
except Exception as e:
    print(f"\n‚ùå Error al leer el archivo CSV: {e}")
    exit(1)

# Verificar que hay suficientes datos
if len(df) < 5:
    print(f"\n‚ö†Ô∏è  Advertencia: Solo {len(df)} episodios. Se necesitan m√°s datos para gr√°ficas significativas.")

# ==================== GR√ÅFICA 1: RECOMPENSA POR EPISODIO ====================
print("\nGenerando gr√°fica de recompensas...")
fig, ax = plt.subplots(figsize=(12, 6))

# Recompensa por episodio
ax.plot(df.index, df['r'], alpha=0.3, label='Recompensa por episodio', color='blue')

# Media m√≥vil (ventana adaptativa)
window = min(50, max(5, len(df) // 10))
if window > 1:
    rolling_mean = df['r'].rolling(window=window, center=False).mean()
    ax.plot(df.index, rolling_mean, label=f'Media m√≥vil ({window} eps)', 
            color='red', linewidth=2)

ax.set_xlabel('Episodio', fontsize=12)
ax.set_ylabel('Recompensa Total', fontsize=12)
ax.set_title('Evoluci√≥n de la Recompensa durante el Entrenamiento', fontsize=14, fontweight='bold')
ax.grid(True, alpha=0.3)
ax.legend(fontsize=10)
ax.axhline(y=0, color='black', linestyle='--', linewidth=0.5, alpha=0.3)

plt.tight_layout()
plt.savefig(os.path.join(OUTPUT_DIR, 'recompensa_por_episodio.png'), dpi=300, bbox_inches='tight')
print(f"‚úÖ Guardado: {OUTPUT_DIR}recompensa_por_episodio.png")
plt.close()

# ==================== GR√ÅFICA 2: DURACI√ìN DE EPISODIOS ====================
print("Generando gr√°fica de duraci√≥n...")
fig, ax = plt.subplots(figsize=(12, 6))

ax.plot(df.index, df['l'], alpha=0.3, label='Duraci√≥n (pasos)', color='green')

if window > 1:
    rolling_mean = df['l'].rolling(window=window, center=False).mean()
    ax.plot(df.index, rolling_mean, label=f'Media m√≥vil ({window} eps)', 
            color='darkgreen', linewidth=2)

ax.set_xlabel('Episodio', fontsize=12)
ax.set_ylabel('Duraci√≥n (pasos)', fontsize=12)
ax.set_title('Duraci√≥n de los Episodios', fontsize=14, fontweight='bold')
ax.grid(True, alpha=0.3)
ax.legend(fontsize=10)

plt.tight_layout()
plt.savefig(os.path.join(OUTPUT_DIR, 'duracion_episodios.png'), dpi=300, bbox_inches='tight')
print(f"‚úÖ Guardado: {OUTPUT_DIR}duracion_episodios.png")
plt.close()

# ==================== GR√ÅFICA 3: ESTAD√çSTICAS FINALES ====================
print("Generando resumen estad√≠stico...")
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# Estad√≠sticas por cuartiles
n_episodes = len(df)
n_quartiles = min(4, n_episodes)  # Usar menos cuartiles si hay pocos datos
quartiles = np.array_split(df, n_quartiles)

quartile_stats = []
for i, q in enumerate(quartiles):
    quartile_stats.append({
        'Cuartil': f'{i+1}',
        'Media': q['r'].mean(),
        'Std': q['r'].std(),
        'Max': q['r'].max(),
        'Min': q['r'].min()
    })

quartile_df = pd.DataFrame(quartile_stats)

# a) Histograma de recompensas
bins = min(30, max(10, len(df) // 10))
axes[0, 0].hist(df['r'], bins=bins, alpha=0.7, color='skyblue', edgecolor='black')
axes[0, 0].axvline(df['r'].mean(), color='red', linestyle='--', linewidth=2, 
                    label=f'Media: {df["r"].mean():.2f}')
axes[0, 0].set_xlabel('Recompensa Total', fontsize=10)
axes[0, 0].set_ylabel('Frecuencia', fontsize=10)
axes[0, 0].set_title('Distribuci√≥n de Recompensas', fontweight='bold')
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)

# b) Boxplot por cuartiles
if n_quartiles > 1:
    axes[0, 1].boxplot([q['r'].values for q in quartiles], 
                        labels=[f'Q{i+1}' for i in range(n_quartiles)])
    axes[0, 1].set_xlabel('Cuartil del Entrenamiento', fontsize=10)
    axes[0, 1].set_ylabel('Recompensa', fontsize=10)
    axes[0, 1].set_title('Recompensa por Cuartil de Entrenamiento', fontweight='bold')
    axes[0, 1].grid(True, alpha=0.3, axis='y')
else:
    axes[0, 1].text(0.5, 0.5, 'Pocos datos\npara cuartiles', 
                    ha='center', va='center', fontsize=12)
    axes[0, 1].set_title('Recompensa por Cuartil', fontweight='bold')

# c) Mejora progresiva
colors = ['#ff9999', '#ffcc99', '#99ccff', '#99ff99'][:n_quartiles]
axes[1, 0].bar(quartile_df['Cuartil'], quartile_df['Media'], 
               alpha=0.7, color=colors)
axes[1, 0].set_xlabel('Cuartil', fontsize=10)
axes[1, 0].set_ylabel('Recompensa Media', fontsize=10)
axes[1, 0].set_title('Mejora Progresiva por Cuartil', fontweight='bold')
axes[1, 0].grid(True, alpha=0.3, axis='y')

# d) Tabla de resumen
axes[1, 1].axis('off')

mejora = quartile_df.iloc[-1]["Media"] - quartile_df.iloc[0]["Media"] if n_quartiles > 1 else 0

table_data = [
    ['M√©trica', 'Valor'],
    ['Episodios totales', f'{n_episodes}'],
    ['Recompensa media', f'{df["r"].mean():.2f} ¬± {df["r"].std():.2f}'],
    ['Recompensa m√°xima', f'{df["r"].max():.2f}'],
    ['Recompensa m√≠nima', f'{df["r"].min():.2f}'],
    ['Duraci√≥n media', f'{df["l"].mean():.1f} pasos'],
    ['Mejora Q1‚ÜíQ{}'.format(n_quartiles), f'{mejora:.2f}'],
]
table = axes[1, 1].table(cellText=table_data, cellLoc='left', loc='center',
                         colWidths=[0.5, 0.5])
table.auto_set_font_size(False)
table.set_fontsize(10)
table.scale(1, 2)

# Estilo para la tabla
for i, cell in table.get_celld().items():
    if i[0] == 0:  # Header
        cell.set_facecolor('#4CAF50')
        cell.set_text_props(weight='bold', color='white')
    else:
        cell.set_facecolor('#f0f0f0' if i[0] % 2 == 0 else 'white')

plt.suptitle('Resumen del Entrenamiento', fontsize=16, fontweight='bold', y=0.995)
plt.tight_layout(rect=[0, 0, 1, 0.98])
plt.savefig(os.path.join(OUTPUT_DIR, 'resumen_entrenamiento.png'), dpi=300, bbox_inches='tight')
print(f"‚úÖ Guardado: {OUTPUT_DIR}resumen_entrenamiento.png")
plt.close()

# ==================== ESTAD√çSTICAS EN CONSOLA ====================
print(f"\n{'='*60}")
print(f"RESUMEN DEL ENTRENAMIENTO")
print(f"{'='*60}")
print(f"üìä Episodios totales: {n_episodes}")
print(f"üéØ Recompensa media: {df['r'].mean():.2f} ¬± {df['r'].std():.2f}")
print(f"üìà Recompensa m√°xima: {df['r'].max():.2f}")
print(f"üìâ Recompensa m√≠nima: {df['r'].min():.2f}")
print(f"‚è±Ô∏è  Duraci√≥n media: {df['l'].mean():.1f} pasos")
if n_quartiles > 1:
    print(f"üìä Mejora Q1‚ÜíQ{n_quartiles}: {mejora:.2f}")

# An√°lisis de aprendizaje
print(f"\n{'='*60}")
print("AN√ÅLISIS DE APRENDIZAJE")
print(f"{'='*60}")

if n_episodes < 50:
    print("‚ö†Ô∏è  Pocos episodios para an√°lisis concluyente")
elif mejora > 0:
    print("‚úÖ El modelo muestra MEJORA progresiva")
    if mejora > 5:
        print("   üëç Mejora significativa - buen progreso")
    else:
        print("   üìä Mejora leve - considera m√°s entrenamiento")
else:
    print("‚ö†Ô∏è  Sin mejora clara - revisa hiperpar√°metros o recompensas")

# Recomendaciones
if df['r'].mean() < 0:
    print("\nüí° Recomendaci√≥n: Recompensa media negativa")
    print("   - Considera recompensas m√°s generosas")
    print("   - O m√°s timesteps de entrenamiento")
elif df['r'].mean() < 5:
    print("\nüí° Recomendaci√≥n: Aprendizaje inicial")
    print("   - Aumenta timesteps para mejor resultado")
    print("   - El modelo est√° comenzando a aprender")
else:
    print("\n‚úÖ El modelo ha aprendido comportamientos √∫tiles")

print(f"{'='*60}\n")

print("üìä Todas las gr√°ficas guardadas en:", OUTPUT_DIR)
print("\nüí° Para visualizar m√©tricas detalladas en TensorBoard:")
print(f"   tensorboard --logdir {LOGS_DIR}")

plt.show()